<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>Scrapy模拟登陆豆瓣抓取数据 | Good Coding</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="Go Ahead">
  
  <meta name="description" content="通常情况下，我们都会自己去编写完整的代码来进行数据抓取，但是对于爬取量较大的时候，我们所编写的程序在时间上说不定就没有什么优势了，虽然可以通过多进程、异步等操作来减少爬取时间，但是由于异步编写起来过于复杂(多进程还是挺简单的)，并且需要大量的重构代码。那有没有什么简单的方法来实现大量数据的快速抓取呢？当然有，那就是使用Scrapy框架，其是一个快速、高层次的屏幕抓取和web抓取框架，能够实现快速的">
<meta name="keywords" content="模拟登陆,Scrapy">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy模拟登陆豆瓣抓取数据">
<meta property="og:url" content="http://liyanfei123.github.io/2019/02/26/Scrapy模拟登陆豆瓣抓取数据/index.html">
<meta property="og:site_name" content="Good Coding">
<meta property="og:description" content="通常情况下，我们都会自己去编写完整的代码来进行数据抓取，但是对于爬取量较大的时候，我们所编写的程序在时间上说不定就没有什么优势了，虽然可以通过多进程、异步等操作来减少爬取时间，但是由于异步编写起来过于复杂(多进程还是挺简单的)，并且需要大量的重构代码。那有没有什么简单的方法来实现大量数据的快速抓取呢？当然有，那就是使用Scrapy框架，其是一个快速、高层次的屏幕抓取和web抓取框架，能够实现快速的">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190225211807993.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190225213009521.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjkzNzU4,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190225225641611.png">
<meta property="og:updated_time" content="2019-05-04T09:42:10.042Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scrapy模拟登陆豆瓣抓取数据">
<meta name="twitter:description" content="通常情况下，我们都会自己去编写完整的代码来进行数据抓取，但是对于爬取量较大的时候，我们所编写的程序在时间上说不定就没有什么优势了，虽然可以通过多进程、异步等操作来减少爬取时间，但是由于异步编写起来过于复杂(多进程还是挺简单的)，并且需要大量的重构代码。那有没有什么简单的方法来实现大量数据的快速抓取呢？当然有，那就是使用Scrapy框架，其是一个快速、高层次的屏幕抓取和web抓取框架，能够实现快速的">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20190225211807993.png">
  
  
    <link rel="icon" href="images/touxiang.jpg">
  
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  <script src="/js/pace.min.js"></script>
  

  
  

</head>
</html>
<body>
  <div id="container">
      <header id="header">
    <div id="banner"></div>
    <div id="header-outer">
        <div id="header-menu" class="header-menu-pos animated">
            <div class="header-menu-container">
                <a href="/" class="left">
                    <span class="site-title">Li yanfei&#39;s Blog</span>
                </a>
                <nav id="header-menu-nav" class="right">
                    
                    <a href="/">
                        <i class="fa fa-home"></i>
                        <span>Home</span>
                    </a>
                    
                    <a href="/archives">
                        <i class="fa fa-archive"></i>
                        <span>Archives</span>
                    </a>
                    
                    <a href="/about">
                        <i class="fa fa-user"></i>
                        <span>About</span>
                    </a>
                    
                </nav>
                <a class="mobile-header-menu-button">
                    <i class="fa fa-bars"></i>
                </a>
            </div>
        </div>
        <div id="header-row">
            <div id="logo">
                <a href="/">
                    <img src="/images/logo.png" alt="logo">
                </a>
            </div>
            <div class="header-info">
                <div id="header-title">
                    
                    <h2>
                        Li yanfei&#39;s Blog
                    </h2>
                    
                </div>
                <div id="header-description">
                    
                    <h3>
                        好好学习，天天向上
                    </h3>
                    
                </div>
            </div>
            <nav class="header-nav">
                <div class="social">
                    
                        <a title="Github" target="_blank" href="https://github.com/liyanfei123">
                            <i class="fa fa-github fa-2x"></i></a>
                    
                        <a title="Weibo" target="_blank" ">
                            <i class="fa fa-weibo fa-2x"></i></a>
                    
                        <a title="Twitter" target="_blank" ">
                            <i class="fa fa-twitter fa-2x"></i></a>
                    
                </div>
            </nav>
        </div>
    </div>
</header>
      <div class="outer">
        <section id="main" class="body-wrap"><article id="post-Scrapy模拟登陆豆瓣抓取数据" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="post-title" itemprop="name">
      Scrapy模拟登陆豆瓣抓取数据
    </h1>
    <div class="post-title-bar">
      <ul>
          
              <li>
                  <i class="fa fa-book"></i>
                  
                      <a href="/categories/Python/">Python</a>
                  
              </li>
          
        <li>
          <i class="fa fa-calendar"></i>  2019-02-26
        </li>
        <li>
          <i class="fa fa-eye"></i>
          <span id="busuanzi_value_page_pv"></span>
        </li>
      </ul>
    </div>
  

          
      </header>
    
    <div class="article-entry post-content" itemprop="articleBody">
      
            
            <p>通常情况下，我们都会自己去编写完整的代码来进行数据抓取，但是对于爬取量较大的时候，我们所编写的程序在时间上说不定就没有什么优势了，虽然可以通过多进程、异步等操作来减少爬取时间，但是由于异步编写起来过于复杂(多进程还是挺简单的)，并且需要大量的重构代码。那有没有什么简单的方法来实现大量数据的快速抓取呢？当然有，那就是使用<code>Scrapy</code>框架，其是一个快速、高层次的屏幕抓取和web抓取框架，能够实现快速的数据抓取。</p>
<p>之前我们讲了使用<code>requests.Session()</code>来实现，虽然比较简单，但是现在各大公司在招聘员工时都需要熟悉<code>Scrapy</code>框架，因此，今天就来谈一谈如何用<code>Scrapy</code>来模拟登陆并对数据进行抓取。</p>
<p><img src="https://img-blog.csdnimg.cn/20190225211807993.png" alt="在这里插入图片描述"></p>
<h3 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h3><p>在<code>Scrapy</code>中可直接用<code>Scrapy</code>命令来生产，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject Alita</span><br></pre></td></tr></table></figure></p>
<p>这里Alita是我们所创建的文件夹名称。</p>
<h3 id="创建Spider"><a href="#创建Spider" class="headerlink" title="创建Spider"></a>创建Spider</h3><p>Spider是我们自己定义的类，<code>Scrapy</code>用它来对网页进行抓取并进行解析。同样，Spider的创建页可以通过命令行来实现，在这里，我们要在刚刚创建的alita文件夹中执行命令</p>
<p>Tip：可直接进入到该文件夹下，按住Shift，在按下鼠标左键，可快速进入该文件夹下的命令窗口<br><img src="https://img-blog.csdnimg.cn/20190225213009521.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjkzNzU4,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider alita douban.com</span><br><span class="line">或者</span><br><span class="line">scrapy genspider -t crawl alita douban.com  # 这个在创建时使用的是模板crawl</span><br></pre></td></tr></table></figure></p>
<p>这里需要注意的是<strong>Spider的名称不能和项目的名称重复。</strong></p>
<p>创建后的<code>alita.py</code>的内容为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlitaSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'alita'</span></span><br><span class="line">    allowed_domains = [<span class="string">'douban.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://douban.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<h3 id="创建容器Item"><a href="#创建容器Item" class="headerlink" title="创建容器Item"></a>创建容器Item</h3><p>创建容器，顾名思义就是要创建一个来存放爬取的数据东西，也就是创建Item，它的使用方法和字典相似。在这里，我们要抓取的是’用户昵称’，’评分’，’评论’，’觉得有用的人数’。</p>
<p>由于在创建项目时,创建了 <code>items.py</code>, 因此我们只需要对其内容进行修改，改为我们所需要的字段，代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlitaItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    user_nick = scrapy.Field()</span><br><span class="line">    score = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()                       </span><br><span class="line">    userful_num = scrapy.Field()</span><br></pre></td></tr></table></figure></p>
<h3 id="解析Response，使用Item"><a href="#解析Response，使用Item" class="headerlink" title="解析Response，使用Item"></a>解析Response，使用Item</h3><p>本来这里应该是先讲模拟登陆，生成Request请求的，但考虑到内容过多，就放到后面来讲。在<code>Scrapy</code>将网页下载下来后，对response变量的内容解析，并将我们所需要的内容提取出来赋值给Item字段，<code>alita.py</code>中部分代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    results = response.css(<span class="string">'div.comment-item'</span>)</span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">        item = AlitaItem()</span><br><span class="line">        item[<span class="string">'user_nick'</span>] = result.css(<span class="string">'span.comment-info &gt; a::text'</span>).extract_first()</span><br><span class="line">        item[<span class="string">'score'</span>] = result.css(<span class="string">'span.rating::attr(title)'</span>).extract_first()</span><br><span class="line">        item[<span class="string">'content'</span>] = result.css(<span class="string">'span.short::text'</span>).extract_first()</span><br><span class="line">        item[<span class="string">'userful_num'</span>] = result.css(<span class="string">'span.votes::text'</span>).extract_first()</span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>
<p>我们使用了CSS选择器来对数据进行提取，具体的表达式再此就不进行阐述了。大家可在<a href="http://www.w3school.com.cn/cssref/css_selectors.asp" target="_blank" rel="noopener">w3cschool</a>中找到详细的讲解。</p>
<h3 id="模拟登陆"><a href="#模拟登陆" class="headerlink" title="模拟登陆"></a>模拟登陆</h3><p>用<code>Scrapy</code>来进行模拟登陆的方法主要有三种：</p>
<p><strong>1.自己直接登陆网站，将登陆成功的<code>cookies</code>保存下来，供<code>Scrapy</code>直接携带</strong></p>
<p>   对于该方法不进行展开，毕竟有些网站的<code>cookies</code>会发生变化，短时间内保存下来的<code>cookies</code>再进行模拟登陆时会成功，但是过段时间就不行，因此，对于这种方法并不推荐。当然，没有其他办法的时候，还是可以使用该类方法的（如登陆时需要验证码，验证码较为复杂，或者由一些加密的难以破解的数据）</p>
<p><strong>2.使用<code>scrapy.Formrequest.from_response()</code>进行登陆， 自动解析当前登陆url，找到表单，发送post请求</strong></p>
<p>   该方法对于大对数网站来说应该都可以实现，因为它能够实现自动解析得到表单，并发送post请求，这能给我们的编程带来极大的便利。 该方法的关键就是对表单进行填写，然后通过<code>scrapy.Formrequest.from_response()</code>进行提交便可以了，在这过程中<code>from_response()</code>用来模拟表单上的提交单击。</p>
<p> 你可能会问，表单中的内容如何填写呢？不用担心，直接在<code>parse</code>函数中写入即可。<strong>注意的是在这里我们要对<code>start_urls</code>进行设置，将其设置为登陆请求的url，<code>parse</code>将对<code>start_urls</code>中返回的response进行解析，进行进一步处理</strong>。</p>
<p> 代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlitaSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'alita'</span></span><br><span class="line">    allowed_domains = [<span class="string">'douban.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'https://accounts.douban.com/j/mobile/login/basic'</span>]    <span class="comment"># 需要登陆的url</span></span><br><span class="line">    base_url = <span class="string">'https://movie.douban.com/subject/1652592/comments?start=&#123;&#125;&amp;limit=20&amp;sort=new_score&amp;status=P'</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        postData = &#123;</span><br><span class="line">            <span class="string">'ck'</span>: <span class="string">''</span>,</span><br><span class="line">            <span class="string">'name'</span>: <span class="string">'****'</span>,      <span class="comment"># 用户名</span></span><br><span class="line">            <span class="string">'password'</span>: <span class="string">'****'</span>,  <span class="comment"># 密码</span></span><br><span class="line">            <span class="string">'remember'</span>: <span class="string">'false'</span>,</span><br><span class="line">            <span class="string">'ticket'</span>: <span class="string">''</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> [FormRequest.from_response(response, formdata = postData, callback = self.after_login, dont_filter = <span class="literal">True</span>)]</span><br></pre></td></tr></table></figure>
<p>这里callback回调函数设置的是需要登陆成功后才能进行的一些网页请求。</p>
<p>很不幸的是，在使用该方法进行模拟登陆时，<code>Scrapy</code>的某条Debug显示为403<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2019-02-25 22:52:55 [scrapy.core.engine] DEBUG: Crawled (403) &lt;GET https://accounts.douban.com/j/mobile/login/basic&gt; (referer: None)</span><br></pre></td></tr></table></figure></p>
<p>并且报错信息（截取部分）为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> raise ValueError(&quot;No &lt;form&gt; element found in %s&quot; % response)</span><br><span class="line">ValueError: No &lt;form&gt; element found in &lt;403 https://accounts.douban.com/j/mobile/login/basic&gt;</span><br></pre></td></tr></table></figure></p>
<p>通过报错信息我们知道时，在解析的response中并没有表单信息存在，这是因为<code>from_response()</code>会对得到的response进行form表单的提取，<strong>因此在使用该方法时，一定要确保response中有form表单，否则，都会出现上述的错误</strong>，比如我们这里的豆瓣登陆界面就时不存在form表单的，用浏览器打开请求链接，我们只能看到如下的界面(一般都是空白的界面)<br><img src="https://img-blog.csdnimg.cn/20190225225641611.png" alt="在这里插入图片描述"><br><strong>使用该方法，确保response中有form表单！！！</strong><br><strong>使用该方法，确保response中有form表单！！！</strong><br><strong>使用该方法，确保response中有form表单！！！</strong></p>
<p>因此，在这里想让该方法可行，只需要将<code>start_urls</code>内容修改为我们可见的登陆界面<a href="https://accounts.douban.com/passport/login即可。" target="_blank" rel="noopener">https://accounts.douban.com/passport/login即可。</a></p>
<p><strong>3.使用scrapy.FormRequest()进行登陆，对设置的url发送post请求，对得到的<code>cookies</code>进行存储</strong></p>
<p>既然让函数自己去找表单行不通，那我们就自己来呗。不过在这里同样需要用到<code>FormRequest()</code>，只是不再使用<code>from_response()</code>。</p>
<p>直接上代码：</p>
<p>而是用了FormRequest实例，手动指定post地址，meta参数同样是要带上的，将response.meta[‘cookiejar’]赋值给cookiejar，供后面的Request使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [Request(url = <span class="string">'https://movie.douban.com'</span>, meta = &#123;<span class="string">'cookiejar'</span>:<span class="number">1</span>&#125;, callback = self.post_login)]</span><br><span class="line">   </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">post_login</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> FormRequest(</span><br><span class="line">        url = <span class="string">'https://accounts.douban.com/j/mobile/login/basic'</span>, </span><br><span class="line">        method = <span class="string">'POST'</span>,    <span class="comment"># 指定访问方式</span></span><br><span class="line">        formdata = &#123;</span><br><span class="line">        <span class="string">'ck'</span>: <span class="string">''</span>,</span><br><span class="line">        <span class="string">'name'</span>: <span class="string">'***'</span>,</span><br><span class="line">        <span class="string">'password'</span>: <span class="string">'***'</span>,</span><br><span class="line">        <span class="string">'remember'</span>: <span class="string">'false'</span>,</span><br><span class="line">        <span class="string">'ticket'</span>: <span class="string">''</span></span><br><span class="line">        &#125;,</span><br><span class="line">        meta = &#123;<span class="string">'cookiejar'</span>:response.meta[<span class="string">'cookiejar'</span>]&#125;, </span><br><span class="line">        dont_filter = <span class="literal">True</span>,    <span class="comment"># 不进行去重处理</span></span><br><span class="line">        callback = self.after_login</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">after_login</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">22</span>, <span class="number">24</span>):</span><br><span class="line">        url = self.base_url.format(i * <span class="number">20</span>)</span><br><span class="line">        <span class="keyword">yield</span> Request(url = url, meta = &#123;<span class="string">'cookiejar'</span>:<span class="number">1</span>&#125;, callback = self.parse_item, dont_filter = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>在<code>start_requests</code>中，会默认使用<code>start_urls</code>里面的url来构造Request，在这里我们直接在Request中指定了url，让spider先去访问豆瓣首页（以获取一些隐藏的表单项，在豆瓣登陆里其实并没有什么隐藏的表单项）。<strong><code>start_requests</code>必须返回应该可迭代的对象，因此我们在return后面加了‘[ ]’</strong>。之后通过回调函数来发送post请求。</p>
<p>在<code>post_login</code>中，我们指定访问方式为post，通过meta参数将response.meta[‘cookiejar’]赋值给cookiejar，供后续的Request使用，并不进行过滤处理。在登陆成功之后，通过回调函数用得到的<code>cookies</code>来生成我们要抓取的页面的Request，同样不进行过滤处理。</p>
<p><code>alita.py</code>中的完整代码为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule, Request</span><br><span class="line"><span class="keyword">from</span> alita.items <span class="keyword">import</span> AlitaItem</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> FormRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlitaSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'alita'</span></span><br><span class="line">    allowed_domains = [<span class="string">'douban.com'</span>]</span><br><span class="line">    base_url = <span class="string">'https://movie.douban.com/subject/1652592/comments?start=&#123;&#125;&amp;limit=20&amp;sort=new_score&amp;status=P'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> [Request(url = <span class="string">'https://movie.douban.com'</span>, meta = &#123;<span class="string">'cookiejar'</span>:<span class="number">1</span>&#125;, callback = self.post_login)]</span><br><span class="line">        </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">post_login</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> FormRequest(</span><br><span class="line">            url = <span class="string">'https://accounts.douban.com/j/mobile/login/basic'</span>, </span><br><span class="line">            method = <span class="string">'POST'</span>,</span><br><span class="line">            formdata = &#123;</span><br><span class="line">                <span class="string">'ck'</span>: <span class="string">''</span>,</span><br><span class="line">                <span class="string">'name'</span>: <span class="string">'***'</span>,</span><br><span class="line">                <span class="string">'password'</span>: <span class="string">'***'</span>,</span><br><span class="line">                <span class="string">'remember'</span>: <span class="string">'false'</span>,</span><br><span class="line">                <span class="string">'ticket'</span>: <span class="string">''</span></span><br><span class="line">            &#125;,</span><br><span class="line">            meta = &#123;<span class="string">'cookiejar'</span>:response.meta[<span class="string">'cookiejar'</span>]&#125;,</span><br><span class="line">            dont_filter = <span class="literal">True</span>,</span><br><span class="line">            callback = self.after_login</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">after_login</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">22</span>, <span class="number">24</span>):    <span class="comment"># 20页之后的需要登陆之后才能访问</span></span><br><span class="line">            url = self.base_url.format(i * <span class="number">20</span>)</span><br><span class="line">            <span class="keyword">yield</span> Request(url = url, meta = &#123;<span class="string">'cookiejar'</span>:<span class="number">1</span>&#125;, callback = self.parse_item, dont_filter = <span class="literal">True</span>)   </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        results = response.css(<span class="string">'div.comment-item'</span>)</span><br><span class="line">        <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">            item = AlitaItem()</span><br><span class="line">            item[<span class="string">'user_nick'</span>] = result.css(<span class="string">'span.comment-info &gt; a::text'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'score'</span>] = result.css(<span class="string">'span.rating::attr(title)'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'content'</span>] = result.css(<span class="string">'span.short::text'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'userful_num'</span>] = result.css(<span class="string">'span.votes::text'</span>).extract_first()</span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure></p>
<p>到目前为止，我们的工作已经完成99%了，就差最后一步了。为了能够让Request加入直接登陆后的<code>cookies</code>信息，我们需要在<code>settings.py</code>中的<code>DOWNLOADER_MIDDLEWARES</code><strong>开启中间件<code>scrapy.downloadermiddlewares.cookies.CookiesMiddleware</code></strong><br>关于中间件的更多信息可参阅<br><a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#std:setting-DOWNLOADER_MIDDLEWARES_BASE" target="_blank" rel="noopener">http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#std:setting-DOWNLOADER_MIDDLEWARES_BASE</a></p>
<p>由于豆瓣中存在着反爬虫机制，所以我们还需要增加User-Agent来伪装成浏览器，在这里为了省事儿，我们直接在<code>settings.py</code>中进行了修改</p>
<p>最后得到的<code>settings.py</code>代码为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">BOT_NAME = <span class="string">'alita'</span></span><br><span class="line"></span><br><span class="line">SPIDER_MODULES = [<span class="string">'alita.spiders'</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">'alita.spiders'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span></span><br><span class="line">USER_AGENT = <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">   <span class="string">'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'</span>: <span class="number">700</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="运行程序"><a href="#运行程序" class="headerlink" title="运行程序"></a>运行程序</h3><p>进入目录，运行如下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl alita</span><br></pre></td></tr></table></figure></p>
<p>由于<code>Scrapy</code>的运行结果过长，我们仅截取了部分关键信息放在这里:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">2019-02-26 09:11:00 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://movie.douban.com&gt; (referer: None)</span><br><span class="line">2019-02-26 09:11:00 [scrapy.core.engine] DEBUG: Crawled (200) &lt;POST https://accounts.douban.com/j/mobile/login/basic&gt; (referer: https://movie.douban.com)</span><br><span class="line">2019-02-26 09:11:00 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://movie.douban.com/subject/1652592/comments?start=460&amp;limit=20&amp;sort=new_score&amp;status=P&gt; (referer: https://accounts.douban.com/j/mobile/login/basic)</span><br><span class="line">2019-02-26 09:11:01 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://movie.douban.com/subject/1652592/comments?start=460&amp;limit=20&amp;sort=new_score&amp;status=P&gt;</span><br><span class="line">2019-02-26 09:11:01 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://movie.douban.com/subject/1652592/comments?start=460&amp;limit=20&amp;sort=new_score&amp;status=P&gt;</span><br><span class="line">&#123;&apos;content&apos;: &apos;**********&apos;,</span><br><span class="line"> &apos;score&apos;: &apos;还行&apos;,</span><br><span class="line"> &apos;user_nick&apos;: &apos;*****&apos;,</span><br><span class="line"> &apos;userful_num&apos;: &apos;***&apos;&#125;</span><br><span class="line">2019-02-26 09:11:01 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://movie.douban.com/subject/1652592/comments?start=460&amp;limit=20&amp;sort=new_score&amp;status=P&gt;</span><br><span class="line">&#123;&apos;content&apos;: &apos;*********&apos;,</span><br><span class="line"> &apos;score&apos;: &apos;力荐&apos;,</span><br><span class="line"> &apos;user_nick&apos;: &apos;*****&apos;,</span><br><span class="line"> &apos;userful_num&apos;: &apos;***&apos;&#125;</span><br><span class="line"> ....</span><br></pre></td></tr></table></figure></p>
<p>这里为保护用户信息，我们将评论等内容替换为了‘***’</p>
<p>至此，我们便完整的实现了使用<code>Scrapy</code>模拟登陆豆瓣并对数据进行抓取。后续还可以将数据保存到本地，数据分析，可视化等操作。</p>
<p>好好学习，天天向上。</p>

            <div class="post-copyright">
    <div class="content">
        <p>最后更新： 2019年05月04日 17:42</p>
        <p>原始链接： <a class="post-url" href="/2019/02/26/Scrapy模拟登陆豆瓣抓取数据/" title="Scrapy模拟登陆豆瓣抓取数据">http://liyanfei123.github.io/2019/02/26/Scrapy模拟登陆豆瓣抓取数据/</a></p>
        <footer>
            <a href="http://liyanfei123.github.io">
                <img src="/images/logo.png" alt="Li yanfei">
                Li yanfei
            </a>
        </footer>
    </div>
</div>

      
        
            
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;">赏</a>
</div>

<div id="reward" class="post-modal reward-lay">
    <a class="close" href="javascript:;" id="reward-close">×</a>
    <span class="reward-title">
        <i class="icon icon-quote-left"></i>
        小奶糖
        <i class="icon icon-quote-right"></i>
    </span>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/images/wechat_code.jpg" alt="打赏二维码">
        </div>
        <div class="reward-select">
            
            <label class="reward-select-item checked" data-id="wechat" data-wechat="/images/wechat_code.jpg">
                <img class="reward-select-item-wechat" src="/images/wechat.png" alt="微信">
            </label>
            
            
            <label class="reward-select-item" data-id="alipay" data-alipay="/images/alipay_code.jpg">
                <img class="reward-select-item-alipay" src="/images/alipay.png" alt="支付宝">
            </label>
            
        </div>
    </div>
</div>


        
    </div>
    <footer class="article-footer">
        
        
<div class="post-share">
    <a href="javascript:;" id="share-sub" class="post-share-fab">
        <i class="fa fa-share-alt"></i>
    </a>
    <div class="post-share-list" id="share-list">
        <ul class="share-icons">
          <li>
            <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://liyanfei123.github.io/2019/02/26/Scrapy模拟登陆豆瓣抓取数据/&title=《Scrapy模拟登陆豆瓣抓取数据》 — Good Coding&pic=images/blogs/Scrapy模拟登陆豆瓣抓取数据.jpg" data-title="微博">
              <i class="fa fa-weibo"></i>
            </a>
          </li>
          <li>
            <a class="weixin share-sns" id="wxFab" href="javascript:;" data-title="微信">
              <i class="fa fa-weixin"></i>
            </a>
          </li>
          <li>
            <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://liyanfei123.github.io/2019/02/26/Scrapy模拟登陆豆瓣抓取数据/&title=《Scrapy模拟登陆豆瓣抓取数据》 — Good Coding&source=" data-title="QQ">
              <i class="fa fa-qq"></i>
            </a>
          </li>
          <li>
            <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://liyanfei123.github.io/2019/02/26/Scrapy模拟登陆豆瓣抓取数据/" data-title="Facebook">
              <i class="fa fa-facebook"></i>
            </a>
          </li>
          <li>
            <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Scrapy模拟登陆豆瓣抓取数据》 — Good Coding&url=http://liyanfei123.github.io/2019/02/26/Scrapy模拟登陆豆瓣抓取数据/&via=http://liyanfei123.github.io" data-title="Twitter">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
          <li>
            <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://liyanfei123.github.io/2019/02/26/Scrapy模拟登陆豆瓣抓取数据/" data-title="Google+">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        </ul>
     </div>
</div>
<div class="post-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;" id="wxShare-close">×</a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=http://liyanfei123.github.io/2019/02/26/Scrapy模拟登陆豆瓣抓取数据/" alt="微信分享二维码">
</div>

<div class="mask"></div>

        
        <ul class="article-footer-menu">
            
            
  <li class="article-footer-tags">
    <i class="fa fa-tags"></i>
      
    <a href="/tags/模拟登陆/" class="color5">模拟登陆</a>
      
    <a href="/tags/Scrapy/" class="color2">Scrapy</a>
      
  </li>

        </ul>
        
    </footer>
  </div>
</article>


    <aside class="post-toc-pos post-toc-top" id="post-toc">
        <nav class="post-toc-wrap">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#创建项目"><span class="post-toc-text">创建项目</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#创建Spider"><span class="post-toc-text">创建Spider</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#创建容器Item"><span class="post-toc-text">创建容器Item</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#解析Response，使用Item"><span class="post-toc-text">解析Response，使用Item</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#模拟登陆"><span class="post-toc-text">模拟登陆</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#运行程序"><span class="post-toc-text">运行程序</span></a></li></ol>
        </nav>
    </aside>
    

<nav id="article-nav">
  
    <a href="/2019/03/03/Python-异步-协程-线程-进程/" id="article-nav-newer" class="article-nav-link-wrap">

      <span class="article-nav-title">
        <i class="fa fa-hand-o-left" aria-hidden="true"></i>
        
          Python 异步 协程 线程 进程
        
      </span>
    </a>
  
  
    <a href="/2019/02/24/Python抓取豆瓣-阿丽塔-1/" id="article-nav-older" class="article-nav-link-wrap">
      <span class="article-nav-title">《阿丽塔》到底值不值得看？</span>
      <i class="fa fa-hand-o-right" aria-hidden="true"></i>
    </a>
  
</nav>



    
</section>
        
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info" class="inner">
      
<p>
    <span id="busuanzi_container_site_uv" style="display:none">
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style="display:none">
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


      <p>
        Powered by Lyf
      &copy; 2019 Li yanfei<br>
      <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
      </p>
      <script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("29/04/2019 17:38:00");//在此处修改你的建站时间
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "本站勉强运行 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
    } 
setInterval("createtime()",250);
</script>
    </div>
  </div>
</footer>



    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
  var mihoConfig = {
      root: "http://liyanfei123.github.io",
      animate: true,
      isHome: false,
      share: true,
      reward: 1
  }
</script>
<div class="sidebar">
    <div id="sidebar-search" title="Search">
        <i class="fa fa-search"></i>
    </div>
    <div id="sidebar-category" title="Categories">
        <i class="fa fa-book"></i>
    </div>
    <div id="sidebar-tag" title="Tags">
        <i class="fa fa-tags"></i>
    </div>
    <div id="sidebar-top">
        <span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span>
    </div>
</div>
<div class="sidebar-menu-box" id="sidebar-menu-box">
    <div class="sidebar-menu-box-container">
        <div id="sidebar-menu-box-categories">
            <a class="category-link" href="/categories/Matlab/">Matlab</a><a class="category-link" href="/categories/Python/">Python</a>
        </div>
        <div id="sidebar-menu-box-tags">
            <a href="/tags/Scrapy/" style="font-size: 10px;">Scrapy</a> <a href="/tags/Session/" style="font-size: 10px;">Session</a> <a href="/tags/反爬虫/" style="font-size: 20px;">反爬虫</a> <a href="/tags/异步/" style="font-size: 10px;">异步</a> <a href="/tags/数据分析/" style="font-size: 15px;">数据分析</a> <a href="/tags/模拟登陆/" style="font-size: 15px;">模拟登陆</a> <a href="/tags/生成器/" style="font-size: 10px;">生成器</a> <a href="/tags/稳定性分析/" style="font-size: 10px;">稳定性分析</a> <a href="/tags/线程/" style="font-size: 15px;">线程</a> <a href="/tags/装饰器/" style="font-size: 10px;">装饰器</a> <a href="/tags/进程/" style="font-size: 10px;">进程</a> <a href="/tags/迭代器/" style="font-size: 10px;">迭代器</a>
        </div>
    </div>
    <a href="javascript:;" class="sidebar-menu-box-close">&times;</a>
</div>
<div class="mobile-header-menu-nav" id="mobile-header-menu-nav">
    <div class="mobile-header-menu-container">
        <span class="title">Menus</span>
        <ul class="mobile-header-menu-navbar">
            
            <li>
                <a href="/">
                    <i class="fa fa-home"></i><span>Home</span>
                </a>
            </li>
            
            <li>
                <a href="/archives">
                    <i class="fa fa-archive"></i><span>Archives</span>
                </a>
            </li>
            
            <li>
                <a href="/about">
                    <i class="fa fa-user"></i><span>About</span>
                </a>
            </li>
            
        </ul>
    </div>
    <div class="mobile-header-tag-container">
        <span class="title">Tags</span>
        <div id="mobile-header-container-tags">
            <a href="/tags/Scrapy/" style="font-size: 10px;">Scrapy</a> <a href="/tags/Session/" style="font-size: 10px;">Session</a> <a href="/tags/反爬虫/" style="font-size: 20px;">反爬虫</a> <a href="/tags/异步/" style="font-size: 10px;">异步</a> <a href="/tags/数据分析/" style="font-size: 15px;">数据分析</a> <a href="/tags/模拟登陆/" style="font-size: 15px;">模拟登陆</a> <a href="/tags/生成器/" style="font-size: 10px;">生成器</a> <a href="/tags/稳定性分析/" style="font-size: 10px;">稳定性分析</a> <a href="/tags/线程/" style="font-size: 15px;">线程</a> <a href="/tags/装饰器/" style="font-size: 10px;">装饰器</a> <a href="/tags/进程/" style="font-size: 10px;">进程</a> <a href="/tags/迭代器/" style="font-size: 10px;">迭代器</a>
        </div>
    </div>
</div>
<div class="search-wrap">
    <span class="search-close">&times;</span>
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
            <i class="icon icon-lg icon-chevron-left"></i>
        </a>
        <input class="search-field" placeholder="Search..." id="keywords">
        <a id="search-submit" href="javascript:;">
            <i class="fa fa-search"></i>
        </a>
    <div class="search-container" id="search-container">
        <ul class="search-result" id="search-result">
        </ul>
    </div>
</div>

<div id="search-tpl">
    <li class="search-result-item">
        <a href="{url}" class="search-item-li">
            <span class="search-item-li-title" title="{title}">{title}</span>
        </a>
    </li>
</div>
<script src="/js/search.js"></script>
<script src="/js/main.js"></script>


  <script src="//cdn.bootcss.com/particles.js/2.0.0/particles.min.js"></script>
  <div id="particles"></div>
  <script src="/js/particles.js"></script>







  <link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">
  <script src="//cdn.bootcss.com/scrollReveal.js/3.0.5/scrollreveal.js"></script>
  <script src="/js/animate.js"></script>


  <script src="/js/pop-img.js"></script>
  <script>
     $(".article-entry p img").popImg();
  </script>

  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/assets/tororo.model.json"},"display":{"superSample":2,"width":150,"height":300,"position":"right","hOffset":0,"vOffset":-20},"mobile":{"show":true,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>

<script type="text/javascript" src="http://libs.baidu.com/jquery/1.8.3/jquery.js"></script>
<script type="text/javascript" src="http://libs.baidu.com/jquery/1.8.3/jquery.min.js"></script>
<!-- 雪花特效 -->
<script type="text/javascript" src="\js\snow.js"></script>